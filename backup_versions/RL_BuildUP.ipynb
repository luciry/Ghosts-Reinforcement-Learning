{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib.colors import ListedColormap\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constants for cell states\n",
    "EMPTY = 0\n",
    "GOOD_GHOST_PLAYER = 1\n",
    "BAD_GHOST_PLAYER = 2\n",
    "GOOD_GHOST_OPPONENT = 3\n",
    "BAD_GHOST_OPPONENT = 4\n",
    "OPPONENT_CORNER = 5\n",
    "PLAYER_CORNER = 6\n",
    "\n",
    "# Reward structure\n",
    "REACH_CORNER_REWARD = 100\n",
    "CAPTURE_GOOD_GHOST_PENALTY = -50\n",
    "CAPTURE_BAD_GHOST_REWARD = 50\n",
    "OPPONENT_CAPUTRE_YOUR_GOOD_GHOST_PENALTY = -50\n",
    "OPPONENT_CAPUTRE_YOUR_BAD_GHOST_REWARD = 50\n",
    "OPPONENT_CORNER_REWARD = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GhostsEnv:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((6, 6), dtype=int)\n",
    "        self.ghost_positions = []\n",
    "        self.current_phase = 'placement'\n",
    "        self.current_turn = 1\n",
    "        self.placement_count = 0\n",
    "        self.previous_winning_positions = []\n",
    "      \n",
    "    def reset(self):\n",
    "        self.board = np.zeros((6, 6), dtype=int)\n",
    "        self.ghost_positions = []\n",
    "        self.current_phase = 'placement'\n",
    "        self.current_turn = 1\n",
    "        self.placement_count = 0\n",
    "        # Set corner states\n",
    "        self.board[0, 0] = self.board[0, 5] = OPPONENT_CORNER\n",
    "        self.board[5, 0] = self.board[5, 5] = PLAYER_CORNER\n",
    "        return self.board\n",
    "    \n",
    "    def get_valid_actions(self):\n",
    "        valid_actions = []\n",
    "        if self.current_phase == 'placement':\n",
    "            if self.current_turn == 1:  # Player's turn\n",
    "                rows = [5, 4]\n",
    "            else:  # Opponent's turn\n",
    "                rows = [0, 1]\n",
    "            \n",
    "            for row in rows:\n",
    "                for col in range(1, 5):\n",
    "                    if self.board[row, col] == EMPTY:\n",
    "                        valid_actions.append(4 * (row % 4) + (col - 1))\n",
    "        else:  # Movement phase\n",
    "            for i, (x, y) in enumerate(self.ghost_positions):\n",
    "                if (self.current_turn == 1 and self.board[x, y] in [GOOD_GHOST, BAD_GHOST]) or \\\n",
    "                   (self.current_turn == 2 and self.board[x, y] in [GOOD_GHOST_OPPONENT, BAD_GHOST_OPPONENT]):\n",
    "                    for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                        new_x, new_y = x + dx, y + dy\n",
    "                        if 0 <= new_x < 6 and 0 <= new_y < 6 and self.board[new_x, new_y] == EMPTY:\n",
    "                            valid_actions.append(i * 5 + [(-1, 0), (1, 0), (0, -1), (0, 1)].index((dx, dy)))\n",
    "                    # Add capture action\n",
    "                    for adj_x, adj_y in self.get_adjacent_positions((x, y)):\n",
    "                        if (self.current_turn == 1 and self.board[adj_x, adj_y] in [GOOD_GHOST_OPPONENT, BAD_GHOST_OPPONENT]) or \\\n",
    "                           (self.current_turn == 2 and self.board[adj_x, adj_y] in [GOOD_GHOST, BAD_GHOST]):\n",
    "                            valid_actions.append(i * 5 + 4)\n",
    "                            break\n",
    "        \n",
    "        if not valid_actions:\n",
    "            print(\"Warning: No valid actions available.\")\n",
    "            print(\"Current board state:\")\n",
    "            print(self.board)\n",
    "            print(f\"Current phase: {self.current_phase}\")\n",
    "            print(f\"Current turn: {self.current_turn}\")\n",
    "            print(f\"Placement count: {self.placement_count}\")\n",
    "            print(f\"Ghost positions: {self.ghost_positions}\")\n",
    "        \n",
    "        return valid_actions\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.current_phase == 'placement':\n",
    "            return self.placement_step(action)\n",
    "        else:\n",
    "            return self.movement_step(action)\n",
    "\n",
    "    def placement_step(self, action):\n",
    "        reward = 0\n",
    "        row = 5 if action < 4 else 4 if self.current_turn == 1 else 0 if action < 4 else 1\n",
    "        col = (action % 4) + 1\n",
    "        \n",
    "        if self.current_turn == 1:  # Player's turn\n",
    "            ghost_type = GOOD_GHOST if self.placement_count < 4 else BAD_GHOST\n",
    "        else:  # Opponent's turn\n",
    "            ghost_type = GOOD_GHOST_OPPONENT if random.random() < 0.5 else BAD_GHOST_OPPONENT\n",
    "\n",
    "        self.board[row, col] = ghost_type\n",
    "        self.ghost_positions.append((row, col))\n",
    "        reward = 10 if ghost_type in [GOOD_GHOST, GOOD_GHOST_OPPONENT] else 5\n",
    "        self.placement_count += 1\n",
    "        self.current_turn = 3 - self.current_turn\n",
    "\n",
    "        if self.placement_count == 16:\n",
    "            self.current_phase = 'movement'\n",
    "            reward += self.reward_for_initial_position()\n",
    "\n",
    "        return self.board, reward, False, {}\n",
    "\n",
    "    def movement_step(self, action):\n",
    "        ghost_index = action // 5\n",
    "        direction = action % 5\n",
    "\n",
    "        if direction == 4:  # Capture action\n",
    "            return self.capture_ghost(ghost_index)\n",
    "        else:\n",
    "            return self.move_ghost(ghost_index, direction)\n",
    "\n",
    "    def move_ghost(self, ghost_index, direction):\n",
    "        current_pos = self.ghost_positions[ghost_index]\n",
    "        new_pos = self.get_new_position(current_pos, direction)\n",
    "\n",
    "        ghost_type = self.board[current_pos]\n",
    "        self.board[current_pos] = EMPTY\n",
    "        self.board[new_pos] = ghost_type\n",
    "        self.ghost_positions[ghost_index] = new_pos\n",
    "\n",
    "        reward, done = self.check_win_conditions()\n",
    "        reward += MOVE_PENALTY\n",
    "\n",
    "        self.current_turn = 3 - self.current_turn\n",
    "        return self.board, reward, done, {}\n",
    "\n",
    "    def capture_ghost(self, ghost_index):\n",
    "        current_pos = self.ghost_positions[ghost_index]\n",
    "        adjacent_positions = self.get_adjacent_positions(current_pos)\n",
    "\n",
    "        for pos in adjacent_positions:\n",
    "            if (self.current_turn == 1 and self.board[pos] in [GOOD_GHOST_OPPONENT, BAD_GHOST_OPPONENT]) or \\\n",
    "               (self.current_turn == 2 and self.board[pos] in [GOOD_GHOST, BAD_GHOST]):\n",
    "                captured_ghost = self.board[pos]\n",
    "                if captured_ghost in [BAD_GHOST_OPPONENT, BAD_GHOST]:\n",
    "                    reward = CAPTURE_BAD_GHOST_REWARD\n",
    "                else:\n",
    "                    reward = CAPTURE_GOOD_GHOST_PENALTY\n",
    "                self.board[pos] = EMPTY\n",
    "                self.ghost_positions.remove(pos)\n",
    "                done = self.check_win_conditions()[1]\n",
    "                self.current_turn = 3 - self.current_turn\n",
    "                return self.board, reward, done, {}\n",
    "\n",
    "        return self.board, MOVE_PENALTY, False, {}\n",
    "\n",
    "    def get_new_position(self, current_pos, direction):\n",
    "        x, y = current_pos\n",
    "        if direction == 0:  # Up\n",
    "            return (x - 1, y)\n",
    "        elif direction == 1:  # Down\n",
    "            return (x + 1, y)\n",
    "        elif direction == 2:  # Left\n",
    "            return (x, y - 1)\n",
    "        elif direction == 3:  # Right\n",
    "            return (x, y + 1)\n",
    "\n",
    "    def get_adjacent_positions(self, pos):\n",
    "        x, y = pos\n",
    "        return [(x + dx, y + dy) for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)] if 0 <= x + dx < 6 and 0 <= y + dy < 6]\n",
    "\n",
    "    def check_win_conditions(self):\n",
    "        if self.player_reaches_corner():\n",
    "            self.store_winning_position()\n",
    "            return REACH_CORNER_REWARD, True\n",
    "        elif self.all_good_ghosts_captured():\n",
    "            return CAPTURE_GOOD_GHOST_PENALTY, True\n",
    "        return 0, False\n",
    "\n",
    "    def player_reaches_corner(self):\n",
    "        return self.board[0, 0] == GOOD_GHOST or self.board[0, 5] == GOOD_GHOST\n",
    "\n",
    "    def all_good_ghosts_captured(self):\n",
    "        return np.sum(self.board == GOOD_GHOST) == 0\n",
    "\n",
    "    def reward_for_initial_position(self):\n",
    "        if not self.previous_winning_positions:\n",
    "            return 0\n",
    "        similarity_score = sum(1 for current, previous in zip(self.ghost_positions, self.previous_winning_positions) if current == previous)\n",
    "        return similarity_score * 2\n",
    "\n",
    "    def store_winning_position(self):\n",
    "        self.previous_winning_positions = self.ghost_positions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "class GhostsAgent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = DQN(6*6, 13).to(self.device)  # 6x6 board flattened, 13 possible actions\n",
    "        self.target_model = DQN(6*6, 13).to(self.device)\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        self.optimizer = optim.Adam(self.model.parameters())\n",
    "        self.memory = deque(maxlen=10000)\n",
    "        self.batch_size = 64\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.01\n",
    "        self.update_target_every = 100\n",
    "        self.episode_rewards = []\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state.flatten(), action, reward, next_state.flatten(), done))\n",
    "\n",
    "    def act(self, state):\n",
    "        valid_actions = self.env.get_valid_actions()\n",
    "        if random.random() <= self.epsilon:\n",
    "            return random.choice(valid_actions)\n",
    "        state = torch.FloatTensor(state.flatten()).unsqueeze(0).to(self.device)\n",
    "        q_values = self.model(state)\n",
    "        valid_q_values = q_values[0, valid_actions]\n",
    "        return valid_actions[torch.argmax(valid_q_values).item()]\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        batch = random.sample(self.memory, self.batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        states = torch.FloatTensor(np.array(states)).to(self.device)\n",
    "        actions = torch.LongTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).to(self.device)\n",
    "        next_states = torch.FloatTensor(np.array(next_states)).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).to(self.device)\n",
    "\n",
    "        current_q_values = self.model(states).gather(1, actions.unsqueeze(1))\n",
    "        next_q_values = self.target_model(next_states).max(1)[0].detach()\n",
    "        target_q_values = rewards + (1 - dones) * self.gamma * next_q_values\n",
    "\n",
    "        loss = nn.MSELoss()(current_q_values, target_q_values.unsqueeze(1))\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def train(self, episodes):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        cmap = ListedColormap(['white', 'green', 'red', 'blue', 'yellow', 'purple', 'orange'])\n",
    "\n",
    "        for episode in range(episodes):\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            steps = 0\n",
    "\n",
    "            while not done:\n",
    "                action = self.act(state)\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                self.remember(state, action, reward, next_state, done)\n",
    "\n",
    "                # Visualize the game board\n",
    "                ax1.clear()\n",
    "                ax1.imshow(state, cmap=cmap, vmin=0, vmax=6)\n",
    "                ax1.set_title(f\"Episode {episode}, Step {steps}\")\n",
    "                for i in range(6):\n",
    "                    for j in range(6):\n",
    "                        ax1.text(j, i, str(int(state[i, j])), ha='center', va='center')\n",
    "\n",
    "                # Plot rewards\n",
    "                ax2.clear()\n",
    "                ax2.plot(self.episode_rewards)\n",
    "                ax2.set_title(\"Rewards per Episode\")\n",
    "                ax2.set_xlabel(\"Episode\")\n",
    "                ax2.set_ylabel(\"Total Reward\")\n",
    "\n",
    "                plt.draw()\n",
    "                plt.pause(0.1)\n",
    "\n",
    "                # Print detailed information\n",
    "                print(f\"Episode: {episode}, Step: {steps}\")\n",
    "                print(f\"Action: {action}\")\n",
    "                print(f\"Reward: {reward}\")\n",
    "                print(\"Current State:\")\n",
    "                print(state)\n",
    "                print(\"Next State:\")\n",
    "                print(next_state)\n",
    "                print(f\"Done: {done}\")\n",
    "                print(\"-------------------\")\n",
    "\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "                steps += 1\n",
    "\n",
    "                if len(self.memory) > self.batch_size:\n",
    "                    self.replay()\n",
    "\n",
    "            self.episode_rewards.append(total_reward)\n",
    "            self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "            if episode % self.update_target_every == 0:\n",
    "                self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "            print(f\"Episode {episode} finished. Total Reward: {total_reward}, Steps: {steps}, Epsilon: {self.epsilon:.4f}\")\n",
    "            time.sleep(1)  # Pause between episodes\n",
    "\n",
    "        plt.close()\n",
    "        print(\"Training completed.\")\n",
    "\n",
    "    def visualize_training(self):\n",
    "        episodes = len(self.episode_rewards)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(range(episodes), self.episode_rewards)\n",
    "        plt.title('Reward per Episode')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Reward')\n",
    "        plt.show()\n",
    "\n",
    "        avg_reward = sum(self.episode_rewards) / episodes\n",
    "        max_reward = max(self.episode_rewards)\n",
    "        min_reward = min(self.episode_rewards)\n",
    "\n",
    "        print(f\"Average Reward: {avg_reward:.2f}\")\n",
    "        print(f\"Max Reward: {max_reward}\")\n",
    "        print(f\"Min Reward: {min_reward}\")\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.hist(self.episode_rewards, bins=50)\n",
    "        plt.title('Distribution of Rewards')\n",
    "        plt.xlabel('Reward')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "\n",
    "        window_size = 100\n",
    "        moving_avg = np.convolve(self.episode_rewards, np.ones(window_size)/window_size, mode='valid')\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(range(len(moving_avg)), moving_avg)\n",
    "        plt.title(f'Moving Average of Rewards (Window Size: {window_size})')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Average Reward')\n",
    "        plt.show()\n",
    "\n",
    "    def evaluate(self, episodes):\n",
    "        total_rewards = []\n",
    "        for episode in range(episodes):\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "\n",
    "            while not done:\n",
    "                action = self.act(state)\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                state = next_state\n",
    "                episode_reward += reward\n",
    "\n",
    "                self.env.render_board()\n",
    "                print(f\"Action: {action}, Reward: {reward}\")\n",
    "\n",
    "            total_rewards.append(episode_reward)\n",
    "            print(f\"Episode {episode + 1} finished with total reward: {episode_reward}\")\n",
    "\n",
    "        avg_reward = sum(total_rewards) / episodes\n",
    "        print(f\"Average Reward over {episodes} episodes: {avg_reward:.2f}\")\n",
    "        return avg_reward\n",
    "\n",
    "    def play_games(self, num_games=1, human_player=False):\n",
    "        total_rewards = []\n",
    "        for i in range(num_games):\n",
    "            print(f\"\\nGame {i+1}\")\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            \n",
    "            while not done:\n",
    "                self.env.render_board()\n",
    "                \n",
    "                if human_player and self.env.current_turn == 1:\n",
    "                    action = self.env.get_human_action()\n",
    "                else:\n",
    "                    action = self.act(state)\n",
    "                \n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                total_reward += reward\n",
    "                \n",
    "                print(f\"Action: {action}, Reward: {reward}\")\n",
    "                \n",
    "                state = next_state\n",
    "                self.env.current_turn = 3 - self.env.current_turn  # Switch turns (1 -> 2, 2 -> 1)\n",
    "            \n",
    "            self.env.render_board()\n",
    "            print(f\"Game Over! Total Reward: {total_reward}\")\n",
    "            total_rewards.append(total_reward)\n",
    "        \n",
    "        avg_reward = sum(total_rewards) / num_games\n",
    "        print(f\"\\nAverage Reward over {num_games} games: {avg_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 0\n",
      "Action: 1\n",
      "Reward: 10\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 1 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 1 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 1\n",
      "Action: 5\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 1 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 1 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 2\n",
      "Action: 2\n",
      "Reward: 10\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 1 1 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 1 1 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 3\n",
      "Action: 1\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 4 1 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 4 1 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 4\n",
      "Action: 7\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 0 4 1 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 0 4 1 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 5\n",
      "Action: 1\n",
      "Reward: 10\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 0 3 1 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 0 3 1 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 6\n",
      "Action: 1\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 0 2 1 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 0 2 1 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 7\n",
      "Action: 0\n",
      "Reward: 10\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 3 2 1 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 3 2 1 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 8\n",
      "Action: 0\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 2 1 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 2 1 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 9\n",
      "Action: 2\n",
      "Reward: 10\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 2 3 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 2 3 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 10\n",
      "Action: 2\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 2 2 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 2 2 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 11\n",
      "Action: 1\n",
      "Reward: 10\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 3 2 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 3 2 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 12\n",
      "Action: 0\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 3 2 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 3 2 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 13\n",
      "Action: 1\n",
      "Reward: 10\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 3 2 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 3 2 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 14\n",
      "Action: 0\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 3 2 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 3 2 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 15\n",
      "Action: 7\n",
      "Reward: 10\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 3 2 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 3 2 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Step: 16\n",
      "Action: 74\n",
      "Reward: -50\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 0 2 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 4 0 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [6 2 0 2 0 6]]\n",
      "Done: True\n",
      "-------------------\n",
      "Episode 0 finished. Total Reward: 70, Steps: 17, Epsilon: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 0\n",
      "Action: 5\n",
      "Reward: 10\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [6 0 0 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [6 0 0 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 1\n",
      "Action: 2\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 2\n",
      "Action: 5\n",
      "Reward: 10\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 3\n",
      "Action: 1\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [6 0 4 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [6 0 4 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 4\n",
      "Action: 7\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 0 2 0]\n",
      " [6 0 4 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 0 2 0]\n",
      " [6 0 4 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 5\n",
      "Action: 7\n",
      "Reward: 10\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 0 2 0]\n",
      " [6 0 4 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 0 2 0]\n",
      " [6 0 4 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 6\n",
      "Action: 4\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 4 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 4 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 7\n",
      "Action: 1\n",
      "Reward: 10\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 3 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 3 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 8\n",
      "Action: 4\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 3 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 3 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 9\n",
      "Action: 6\n",
      "Reward: 10\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 3 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 3 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 10\n",
      "Action: 7\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 3 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 3 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 11\n",
      "Action: 1\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 4 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 4 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 12\n",
      "Action: 4\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 4 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 4 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 13\n",
      "Action: 3\n",
      "Reward: 10\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 4 4 3 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 4 4 3 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 14\n",
      "Action: 4\n",
      "Reward: 5\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 4 4 3 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 4 4 3 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 15\n",
      "Action: 4\n",
      "Reward: 10\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 3 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 4 4 3 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 3 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 1 0 2 0]\n",
      " [6 0 4 4 3 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 16\n",
      "Action: 70\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 3 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 1 0 2 0]\n",
      " [6 0 4 4 3 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 3 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 1 0 2 0]\n",
      " [6 0 4 4 3 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 17\n",
      "Action: 5\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 3 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 1 4 2 0]\n",
      " [6 0 4 0 3 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 3 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 1 4 2 0]\n",
      " [6 0 4 0 3 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 18\n",
      "Action: 24\n",
      "Reward: -50\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 3 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 1 4 2 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 3 0 3 3 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 1 4 2 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 19\n",
      "Action: 71\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 1 4 2 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 1 4 2 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 20\n",
      "Action: 20\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 0 1 4 0 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 3 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 0 1 4 0 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 21\n",
      "Action: 47\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 3 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 0 1 4 0 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 3 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 0 1 4 0 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 22\n",
      "Action: 12\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 3 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 1 0 4 0 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 3 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 1 0 4 0 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 23\n",
      "Action: 26\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 3 0 0 3 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 1 0 4 0 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 3 0 0 3 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 1 0 4 0 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 24\n",
      "Action: 33\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 3 0 0 3 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 0 1 4 0 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 3 0 0 3 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 0 1 4 0 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 25\n",
      "Action: 73\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 0 3 0 3 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 0 1 4 0 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 0 3 0 3 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 0 1 4 0 0]\n",
      " [6 0 4 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 26\n",
      "Action: 4\n",
      "Reward: 50\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 0 3 0 3 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 0 1 4 0 0]\n",
      " [6 0 0 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 0 3 0 3 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 0 1 4 0 0]\n",
      " [6 0 0 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 27\n",
      "Action: 6\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 0 3 0 3 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 0 1 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 0 3 0 3 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 0 1 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 28\n",
      "Action: 2\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 0 3 0 3 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 1 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 0 3 0 3 0]\n",
      " [0 2 0 0 2 0]\n",
      " [0 1 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 29\n",
      "Action: 66\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 0 0 0 3 0]\n",
      " [0 2 3 0 2 0]\n",
      " [0 1 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 0 0 0 3 0]\n",
      " [0 2 3 0 2 0]\n",
      " [0 1 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 30\n",
      "Action: 60\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 2 0 0 3 0]\n",
      " [0 0 3 0 2 0]\n",
      " [0 1 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 2 0 0 3 0]\n",
      " [0 0 3 0 2 0]\n",
      " [0 1 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 31\n",
      "Action: 22\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 2 0 3 0 0]\n",
      " [0 0 3 0 2 0]\n",
      " [0 1 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 2 0 3 0 0]\n",
      " [0 0 3 0 2 0]\n",
      " [0 1 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 32\n",
      "Action: 35\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 2 0 3 0 0]\n",
      " [0 1 3 0 2 0]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 2 0 3 0 0]\n",
      " [0 1 3 0 2 0]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 33\n",
      "Action: 40\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 3 0 0]\n",
      " [0 1 3 0 2 0]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 3 0 0]\n",
      " [0 1 3 0 2 0]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 34\n",
      "Action: 18\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 3 0 0]\n",
      " [0 1 3 0 0 2]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 3 0 0]\n",
      " [0 1 3 0 0 2]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 35\n",
      "Action: 22\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 3 0 0 0]\n",
      " [0 1 3 0 0 2]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 3 0 0 0]\n",
      " [0 1 3 0 0 2]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 36\n",
      "Action: 39\n",
      "Reward: -50\n",
      "Current State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 3 0 0 0]\n",
      " [0 1 0 0 0 2]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Next State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 3 0 0 0]\n",
      " [0 1 0 0 0 2]\n",
      " [0 0 0 0 0 0]\n",
      " [6 0 0 4 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 37\n",
      "Action: 5\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 3 0 0 0]\n",
      " [0 1 0 0 0 2]\n",
      " [0 0 0 4 0 0]\n",
      " [6 0 0 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 3 0 0 0]\n",
      " [0 1 0 0 0 2]\n",
      " [0 0 0 4 0 0]\n",
      " [6 0 0 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 38\n",
      "Action: 36\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 3 0 0 0]\n",
      " [0 0 0 0 0 2]\n",
      " [0 1 0 4 0 0]\n",
      " [6 0 0 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 3 0 0 0]\n",
      " [0 0 0 0 0 2]\n",
      " [0 1 0 4 0 0]\n",
      " [6 0 0 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 39\n",
      "Action: 41\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 2 3 0 0 0]\n",
      " [0 0 0 0 0 2]\n",
      " [0 1 0 4 0 0]\n",
      " [6 0 0 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 2 3 0 0 0]\n",
      " [0 0 0 0 0 2]\n",
      " [0 1 0 4 0 0]\n",
      " [6 0 0 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 40\n",
      "Action: 11\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 2 3 0 0 0]\n",
      " [0 0 0 0 0 2]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 3 0 0 0]\n",
      " [0 2 3 0 0 0]\n",
      " [0 0 0 0 0 2]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 41\n",
      "Action: 40\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 3 0 0 0]\n",
      " [0 0 0 0 0 2]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 3 0 0 0]\n",
      " [0 0 0 0 0 2]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 42\n",
      "Action: 64\n",
      "Reward: -50\n",
      "Current State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 0 0 0 2]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 3 0 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 0 0 0 2]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 43\n",
      "Action: 38\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 3 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 0 0 0 2]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 3 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 0 0 0 2]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 44\n",
      "Action: 17\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 3 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 3 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 45\n",
      "Action: 36\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 46\n",
      "Action: 57\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 0 0 5]\n",
      " [0 0 0 3 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 47\n",
      "Action: 35\n",
      "Reward: -1\n",
      "Current State:\n",
      "[[5 0 0 3 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Next State:\n",
      "[[5 0 0 3 0 5]\n",
      " [0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 4 0 0]\n",
      " [6 1 0 0 0 6]]\n",
      "Done: False\n",
      "-------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index 70 is out of bounds for dimension 1 with size 13",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[177], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train the agent\u001b[39;00m\n\u001b[0;32m      5\u001b[0m num_episodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4000\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_episodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Visualize the training results\u001b[39;00m\n\u001b[0;32m      9\u001b[0m agent\u001b[38;5;241m.\u001b[39mvisualize_training()\n",
      "Cell \u001b[1;32mIn[176], line 112\u001b[0m, in \u001b[0;36mGhostsAgent.train\u001b[1;34m(self, episodes)\u001b[0m\n\u001b[0;32m    109\u001b[0m     steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:\n\u001b[1;32m--> 112\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_rewards\u001b[38;5;241m.\u001b[39mappend(total_reward)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon_min, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon_decay)\n",
      "Cell \u001b[1;32mIn[176], line 54\u001b[0m, in \u001b[0;36mGhostsAgent.replay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     51\u001b[0m next_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(np\u001b[38;5;241m.\u001b[39marray(next_states))\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     52\u001b[0m dones \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(dones)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 54\u001b[0m current_q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m next_q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_model(next_states)\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m     56\u001b[0m target_q_values \u001b[38;5;241m=\u001b[39m rewards \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dones) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m next_q_values\n",
      "\u001b[1;31mRuntimeError\u001b[0m: index 70 is out of bounds for dimension 1 with size 13"
     ]
    }
   ],
   "source": [
    "env = GhostsEnv()\n",
    "agent = GhostsAgent(env)\n",
    "\n",
    "# Train the agent\n",
    "num_episodes = 4000\n",
    "agent.train(episodes=num_episodes)\n",
    "\n",
    "# Visualize the training results\n",
    "agent.visualize_training()\n",
    "\n",
    "# Evaluate the agent\n",
    "eval_episodes = 100\n",
    "agent.evaluate(episodes=eval_episodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Game 1\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 0, Reward: 10\n",
      ". G . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 3, Reward: 10\n",
      ". G . . G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 1, Reward: 10\n",
      ". G G . G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 2, Reward: 10\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 5, Reward: 5\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . B . . .\n",
      "\n",
      "Action: 4, Reward: 5\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B . . .\n",
      "\n",
      "Action: 7, Reward: 5\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B . B .\n",
      "\n",
      "Action: 6, Reward: 19\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B B B .\n",
      "\n",
      "Action: 2, Reward: 99\n",
      "G . G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B B B .\n",
      "\n",
      "Game Over! Total Reward: 173\n",
      "\n",
      "Game 2\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 0, Reward: 10\n",
      ". G . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 3, Reward: 10\n",
      ". G . . G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 1, Reward: 10\n",
      ". G G . G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 2, Reward: 10\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 5, Reward: 5\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . B . . .\n",
      "\n",
      "Action: 4, Reward: 5\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B . . .\n",
      "\n",
      "Action: 7, Reward: 5\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B . B .\n",
      "\n",
      "Action: 6, Reward: 19\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B B B .\n",
      "\n",
      "Action: 2, Reward: 99\n",
      "G . G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B B B .\n",
      "\n",
      "Game Over! Total Reward: 173\n",
      "\n",
      "Game 3\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 0, Reward: 10\n",
      ". G . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 3, Reward: 10\n",
      ". G . . G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 1, Reward: 10\n",
      ". G G . G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 2, Reward: 10\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 5, Reward: 5\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . B . . .\n",
      "\n",
      "Action: 4, Reward: 5\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B . . .\n",
      "\n",
      "Action: 7, Reward: 5\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B . B .\n",
      "\n",
      "Action: 6, Reward: 19\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B B B .\n",
      "\n",
      "Action: 2, Reward: 99\n",
      "G . G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B B B .\n",
      "\n",
      "Game Over! Total Reward: 173\n",
      "\n",
      "Game 4\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 0, Reward: 10\n",
      ". G . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 3, Reward: 10\n",
      ". G . . G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 1, Reward: 10\n",
      ". G G . G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 2, Reward: 10\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 5, Reward: 5\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . B . . .\n",
      "\n",
      "Action: 4, Reward: 5\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B . . .\n",
      "\n",
      "Action: 7, Reward: 5\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B . B .\n",
      "\n",
      "Action: 6, Reward: 19\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B B B .\n",
      "\n",
      "Action: 2, Reward: 99\n",
      "G . G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B B B .\n",
      "\n",
      "Game Over! Total Reward: 173\n",
      "\n",
      "Game 5\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 0, Reward: 10\n",
      ". G . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 3, Reward: 10\n",
      ". G . . G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 1, Reward: 10\n",
      ". G G . G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 2, Reward: 10\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      "\n",
      "Action: 5, Reward: 5\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . B . . .\n",
      "\n",
      "Action: 4, Reward: 5\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B . . .\n",
      "\n",
      "Action: 7, Reward: 5\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B . B .\n",
      "\n",
      "Action: 6, Reward: 19\n",
      ". G G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B B B .\n",
      "\n",
      "Action: 2, Reward: 99\n",
      "G . G G G .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". . . . . .\n",
      ". B B B B .\n",
      "\n",
      "Game Over! Total Reward: 173\n",
      "\n",
      "Average Reward over 5 games: 173.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Play games\n",
    "agent.play_games(num_games=5, human_player=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
